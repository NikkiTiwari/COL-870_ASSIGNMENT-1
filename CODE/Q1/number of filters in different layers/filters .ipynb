{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Model  with  3 conv layers with  16,32,64 filters resp"
      ],
      "metadata": {
        "id": "ddtdvzEf50ub"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWPUJT3_4Uwd"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "\n",
        "!unzip '/content/gdrive/MyDrive/2.zip'\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "a = '/content/1/test/aeroplane'\n",
        "path, dirs, files = next(os.walk(a))\n",
        "file_count = len(files)\n",
        "print(file_count)\n",
        "\n",
        "\n",
        "import torch, os\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5, 0.5, 0.5])])\n",
        "\n",
        "\n",
        "train_data_dir = \"/content/1/train\"\n",
        "\n",
        "val_data_dir = \"/content/1/val\"\n",
        "test_data_dir = \"/content/1/test\"\n",
        "# take the dataset from the location nad transform it \n",
        "trainset = torchvision.datasets.ImageFolder(root=train_data_dir, transform=transform)\n",
        "#divide the data into batches with batch_size=4\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=1)\n",
        "print(len(trainset))\n",
        "\n",
        "valnset = torchvision.datasets.ImageFolder(root= val_data_dir, transform=transform)\n",
        "valloader = torch.utils.data.DataLoader(valnset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=1)\n",
        "\n",
        "testset = torchvision.datasets.ImageFolder(root= test_data_dir , transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "\n",
        "# <<<<<<<<<<<<<<<<<<<<< EDIT THE MODEL DEFINITION >>>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "# Try experimenting by changing the following:\n",
        "# 1. number of feature maps in conv layer\n",
        "# 2. Number of conv layers\n",
        "# 3. Kernel size\n",
        "# etc etc.,\n",
        "\n",
        "num_epochs = 50        # desired number of training epochs.\n",
        "learning_rate = 0.001   \n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=256, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=1)\n",
        "        \n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(in_features=1024, out_features=256)\n",
        "        self.fc2 = nn.Linear(in_features=256, out_features=128)\n",
        "        \n",
        "        self.fc3 = nn.Linear(in_features=128, out_features=5)\n",
        "         # 5 is the number of classes here (for batch 3,4,5 out_features is 33)\n",
        "\n",
        "    def forward(self, x): \n",
        "\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool(x)\n",
        "       \n",
        "        \n",
        "        \n",
        "        x = F.avg_pool2d(x, kernel_size=x.shape[2:])\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return x  \n",
        "\n",
        "################### DO NOT EDIT THE BELOW CODE!!! #######################\n",
        "\n",
        "net = Net()\n",
        "\n",
        "# transfer the model to GPU\n",
        "if torch.cuda.is_available():\n",
        "    net = net.cuda()\n",
        "\n",
        "########################################################################\n",
        "# Define a Loss function and optimizer\n",
        "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "# Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
        "\n",
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "num_params = np.sum([p.nelement() for p in net.parameters()])\n",
        "print(num_params, ' parameters')\n",
        "\n",
        "########################################################################\n",
        "# Train the network\n",
        "# ^^^^^^^^^^^^^^^^^^^^\n",
        "\n",
        "def train(epoch, trainloader, optimizer, criterion,net):\n",
        "    running_loss = 0.0\n",
        "    correct=0\n",
        "    total=0\n",
        "    for i, data in enumerate(tqdm(trainloader), 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        if torch.cuda.is_available():\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    \n",
        "\n",
        "    print('epoch %d training loss: %.3f' %\n",
        "            (epoch + 1, running_loss / (len(trainloader))))\n",
        "    print('Accuracy of the network on the train images: %f %%' % (\n",
        "                                    100 * correct / total))\n",
        "    return (100* correct/total)\n",
        "\n",
        "    \n",
        "########################################################################\n",
        "# Let us look at how the network performs on the test dataset.\n",
        "\n",
        "def test(testloader, model):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(testloader):\n",
        "            images, labels = data\n",
        "            if torch.cuda.is_available():\n",
        "                images, labels = images.cuda(), labels.cuda()        \n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    print('Accuracy of the network on the test images: %f %%' % (\n",
        "                                    100 * correct / total))\n",
        "    return (100* correct/total)\n",
        "\n",
        "#########################################################################\n",
        "# get details of classes and class to index mapping in a directory\n",
        "def find_classes(dir):\n",
        "    classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n",
        "    classes.sort()\n",
        "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
        "    return classes, class_to_idx\n",
        "\n",
        "\n",
        "def classwise_test(testloader, model):\n",
        "########################################################################\n",
        "# class-wise accuracy\n",
        "\n",
        "    classes, _ = find_classes(train_data_dir)\n",
        "    n_class = len(classes) # number of classes\n",
        "\n",
        "    class_correct = list(0. for i in range(n_class))\n",
        "    class_total = list(0. for i in range(n_class))\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(testloader):\n",
        "            images, labels = data\n",
        "            if torch.cuda.is_available():\n",
        "                images, labels = images.cuda(), labels.cuda()        \n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            c = (predicted == labels).squeeze()\n",
        "            for i in range(4):\n",
        "                label = labels[i]\n",
        "                class_correct[label] += c[i].item()\n",
        "                class_total[label] += 1\n",
        "\n",
        "    for i in range(n_class):\n",
        "        print('Accuracy of %10s : %2f %%' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
        "\n",
        "print('Start Training')\n",
        "os.makedirs('./models', exist_ok=True)\n",
        "train_accuracies=[]\n",
        "test_accuracies=[]\n",
        "val_accuracies=[]\n",
        "\n",
        "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "    print('epoch ', epoch + 1)\n",
        "    train_accuracy=train(epoch, trainloader, optimizer, criterion,net)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    val_accuracy=test(valloader, net)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "    # test_accuracy=test(testloader, net)\n",
        "    # test_accuracies.append(test_accuracy)\n",
        "#     classwise_test(valloader, net)\n",
        "    # save model checkpoint \n",
        "    torch.save(net.state_dict(), './models/model'+str(epoch)+'.pth')      \n",
        "\n",
        "print('performing test')\n",
        "test_accuracy=test(testloader, net)\n",
        "classwise_test(testloader, net)\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Saving our trained model\n",
        "torch.save(net.state_dict(), './models/bestmodelfilter16.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_accuracies))\n",
        "print(len(val_accuracies))\n",
        "with open(r'trainfilter16.txt', 'w') as fp:\n",
        "  for item in train_accuracies:\n",
        "     fp.write(\"%s\\n\" % item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KBxV5aM8wVt",
        "outputId": "0ee06c42-41fb-44e3-e322-991691c7aec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n",
            "50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(r'valfilter16.txt', 'w') as fp:\n",
        "  for item in train_accuracies:\n",
        "     fp.write(\"%s\\n\" % item)"
      ],
      "metadata": {
        "id": "OwfQ_dpo-LIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs= np.arange(0, 50, 1)\n",
        "  \n",
        "# Assign variables to the y axis part of the curve\n",
        "y = train_accuracies\n",
        "z = val_accuracies\n",
        "  \n",
        "# Plotting both the curves simultaneously\n",
        "plt.plot(epochs, y, color='r', label='train_accuracy')\n",
        "plt.plot(epochs, z, color='g', label='val_accuracy')\n",
        "  \n",
        "# Naming the x-axis, y-axis and the whole graph\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Model Accuracy\")\n",
        "  \n",
        "# Adding legend, which helps us recognize the curve according to it's color\n",
        "plt.legend()\n",
        "  \n",
        "# To load the display window\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "e7qdAdPD-S5e",
        "outputId": "d7a73715-bc92-4abb-e1ac-9bb3237551c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model with 3 conv layers with 256,512,1024 filters resp"
      ],
      "metadata": {
        "id": "EB-wTFq86dW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "\n",
        "!unzip '/content/gdrive/MyDrive/2.zip'\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "a = '/content/1/test/aeroplane'\n",
        "path, dirs, files = next(os.walk(a))\n",
        "file_count = len(files)\n",
        "print(file_count)\n",
        "\n",
        "\n",
        "import torch, os\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5, 0.5, 0.5])])\n",
        "\n",
        "\n",
        "train_data_dir = \"/content/1/train\"\n",
        "\n",
        "val_data_dir = \"/content/1/val\"\n",
        "test_data_dir = \"/content/1/test\"\n",
        "# take the dataset from the location nad transform it \n",
        "trainset = torchvision.datasets.ImageFolder(root=train_data_dir, transform=transform)\n",
        "#divide the data into batches with batch_size=4\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=1)\n",
        "print(len(trainset))\n",
        "\n",
        "valnset = torchvision.datasets.ImageFolder(root= val_data_dir, transform=transform)\n",
        "valloader = torch.utils.data.DataLoader(valnset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=1)\n",
        "\n",
        "testset = torchvision.datasets.ImageFolder(root= test_data_dir , transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "\n",
        "# <<<<<<<<<<<<<<<<<<<<< EDIT THE MODEL DEFINITION >>>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "# Try experimenting by changing the following:\n",
        "# 1. number of feature maps in conv layer\n",
        "# 2. Number of conv layers\n",
        "# 3. Kernel size\n",
        "# etc etc.,\n",
        "\n",
        "num_epochs = 50        # desired number of training epochs.\n",
        "learning_rate = 0.001   \n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        \n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(in_features=64, out_features=128)\n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=128)\n",
        "        \n",
        "        self.fc3 = nn.Linear(in_features=128, out_features=5)\n",
        "        self.fc4= nn.Linear(in_features=128, out_features=5)\n",
        "\n",
        "         # 5 is the number of classes here (for batch 3,4,5 out_features is 33)\n",
        "\n",
        "    def forward(self, x): \n",
        "\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool(x)\n",
        "       \n",
        "        \n",
        "        \n",
        "        x = F.avg_pool2d(x, kernel_size=x.shape[2:])\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return x  \n",
        "\n",
        "################### DO NOT EDIT THE BELOW CODE!!! #######################\n",
        "\n",
        "net = Net()\n",
        "\n",
        "# transfer the model to GPU\n",
        "if torch.cuda.is_available():\n",
        "    net = net.cuda()\n",
        "\n",
        "########################################################################\n",
        "# Define a Loss function and optimizer\n",
        "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "# Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
        "\n",
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "num_params = np.sum([p.nelement() for p in net.parameters()])\n",
        "print(num_params, ' parameters')\n",
        "\n",
        "########################################################################\n",
        "# Train the network\n",
        "# ^^^^^^^^^^^^^^^^^^^^\n",
        "\n",
        "def train(epoch, trainloader, optimizer, criterion,net):\n",
        "    running_loss = 0.0\n",
        "    correct=0\n",
        "    total=0\n",
        "    for i, data in enumerate(tqdm(trainloader), 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        if torch.cuda.is_available():\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    \n",
        "\n",
        "    print('epoch %d training loss: %.3f' %\n",
        "            (epoch + 1, running_loss / (len(trainloader))))\n",
        "    print('Accuracy of the network on the train images: %f %%' % (\n",
        "                                    100 * correct / total))\n",
        "    return (100* correct/total)\n",
        "\n",
        "    \n",
        "########################################################################\n",
        "# Let us look at how the network performs on the test dataset.\n",
        "\n",
        "def test(testloader, model):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(testloader):\n",
        "            images, labels = data\n",
        "            if torch.cuda.is_available():\n",
        "                images, labels = images.cuda(), labels.cuda()        \n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    print('Accuracy of the network on the test images: %f %%' % (\n",
        "                                    100 * correct / total))\n",
        "    return (100* correct/total)\n",
        "\n",
        "#########################################################################\n",
        "# get details of classes and class to index mapping in a directory\n",
        "def find_classes(dir):\n",
        "    classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n",
        "    classes.sort()\n",
        "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
        "    return classes, class_to_idx\n",
        "\n",
        "\n",
        "def classwise_test(testloader, model):\n",
        "########################################################################\n",
        "# class-wise accuracy\n",
        "\n",
        "    classes, _ = find_classes(train_data_dir)\n",
        "    n_class = len(classes) # number of classes\n",
        "\n",
        "    class_correct = list(0. for i in range(n_class))\n",
        "    class_total = list(0. for i in range(n_class))\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(testloader):\n",
        "            images, labels = data\n",
        "            if torch.cuda.is_available():\n",
        "                images, labels = images.cuda(), labels.cuda()        \n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            c = (predicted == labels).squeeze()\n",
        "            for i in range(4):\n",
        "                label = labels[i]\n",
        "                class_correct[label] += c[i].item()\n",
        "                class_total[label] += 1\n",
        "\n",
        "    for i in range(n_class):\n",
        "        print('Accuracy of %10s : %2f %%' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
        "\n",
        "print('Start Training')\n",
        "os.makedirs('./models', exist_ok=True)\n",
        "train_accuracies=[]\n",
        "test_accuracies=[]\n",
        "val_accuracies=[]\n",
        "\n",
        "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "    print('epoch ', epoch + 1)\n",
        "    train_accuracy=train(epoch, trainloader, optimizer, criterion,net)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    val_accuracy=test(valloader, net)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "    # test_accuracy=test(testloader, net)\n",
        "    # test_accuracies.append(test_accuracy)\n",
        "#     classwise_test(valloader, net)\n",
        "    # save model checkpoint \n",
        "    torch.save(net.state_dict(), './models/model'+str(epoch)+'.pth')      \n",
        "\n",
        "print('performing test')\n",
        "test_accuracy=test(testloader, net)\n",
        "classwise_test(testloader, net)\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Saving our trained model\n",
        "torch.save(net.state_dict(), './models/bestmodelfilter16.pth')\n"
      ],
      "metadata": {
        "id": "ryOV_MZk_aY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "from torchsummary import summary\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
        "        \n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(in_features=256, out_features=256)\n",
        "        self.fc2 = nn.Linear(in_features=256, out_features=128)\n",
        "        \n",
        "        self.fc3 = nn.Linear(in_features=128, out_features=5)\n",
        "         # 5 is the number of classes here (for batch 3,4,5 out_features is 33)\n",
        "\n",
        "    def forward(self, x): \n",
        "\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool(x)\n",
        "       \n",
        "        \n",
        "        \n",
        "        x = F.avg_pool2d(x, kernel_size=x.shape[2:])\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return x  \n",
        "\n",
        "################### DO NOT EDIT THE BELOW CODE!!! #######################\n",
        "\n",
        "net = Net()\n",
        "device_name = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
        "modl = Net().to(device_name)\n",
        "summary(modl, (3, 64, 64))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmAj0yC-m_6Q",
        "outputId": "cba7d485-f3f2-47a9-d6b3-8621cd5dadb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 64, 64]           1,792\n",
            "         MaxPool2d-2           [-1, 64, 32, 32]               0\n",
            "            Conv2d-3          [-1, 256, 32, 32]         147,712\n",
            "         MaxPool2d-4          [-1, 256, 16, 16]               0\n",
            "            Conv2d-5          [-1, 256, 16, 16]         590,080\n",
            "         MaxPool2d-6            [-1, 256, 8, 8]               0\n",
            "            Linear-7                  [-1, 256]          65,792\n",
            "            Linear-8                  [-1, 128]          32,896\n",
            "            Linear-9                    [-1, 5]             645\n",
            "================================================================\n",
            "Total params: 838,917\n",
            "Trainable params: 838,917\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 5.63\n",
            "Params size (MB): 3.20\n",
            "Estimated Total Size (MB): 8.88\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o-L0UcoVnK8-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}